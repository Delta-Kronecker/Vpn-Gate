import requests
from bs4 import BeautifulSoup
import re
import time
import os
import zipfile
import csv
import io
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed

# --- Configuration ---
IS_GITHUB = os.getenv('GITHUB_ACTIONS') == 'true'
TELEGRAM_BOT_TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')
TELEGRAM_CHAT_ID = os.getenv('TELEGRAM_CHAT_ID')

MAIN_URL = "https://www.vpngate.net/en/"
MIRROR_LIST_URL = "https://www.vpngate.net/en/sites.aspx"
API_PATH = "api/iphone/"

OUTPUT_FILE = "sstp_hosts.txt"

if not IS_GITHUB:
    OUTPUT_FILE = os.path.join(os.getcwd(), OUTPUT_FILE)

# Ù‡Ø¯Ø± Ù…Ø±ÙˆØ±Ú¯Ø± Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ù…Ø³Ø¯ÙˆØ¯ Ø´Ø¯Ù†
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36"
}

def get_active_mirrors():
    """
    Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª Ø³Ø§ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø¢ÛŒÙ†Ù‡â€ŒØ§ÛŒ ÙØ¹Ø§Ù„ Ø§Ø² ØµÙØ­Ù‡ Ù…Ø®ØµÙˆØµ Ø¢Ù†
    """
    mirrors = []
    print(f"ğŸ” Fetching mirror list from {MIRROR_LIST_URL}...")
    try:
        response = requests.get(MIRROR_LIST_URL, headers=HEADERS, timeout=15)
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø´Ø¨ÛŒÙ‡ Ø¢Ø¯Ø±Ø³ Ù…ÛŒØ±ÙˆØ± Ù‡Ø³ØªÙ†Ø¯
        # Ù…Ø¹Ù…ÙˆÙ„Ø§ Ø¯Ø± ØªÚ¯â€ŒÙ‡Ø§ÛŒ <strong> ÛŒØ§ Ù„ÛŒØ³Øªâ€ŒÙ‡Ø§ Ù‚Ø±Ø§Ø± Ø¯Ø§Ø±Ù†Ø¯
        # Ø§Ù„Ú¯ÙˆÛŒ Ù…ÛŒØ±ÙˆØ±Ù‡Ø§ Ù…Ø¹Ù…ÙˆÙ„Ø§ http://vpngate-IP... Ø§Ø³Øª
        for link in soup.find_all('a', href=True):
            href = link['href']
            if "vpngate" in href and "http" in href and href.count('/') <= 3:
                # ØªÙ…ÛŒØ² Ú©Ø±Ø¯Ù† URL (Ø­Ø°Ù Ø§Ø³Ù„Ø´ Ø¢Ø®Ø±)
                clean_url = href.rstrip('/')
                if clean_url not in mirrors:
                    mirrors.append(clean_url)
        
        print(f"âœ… Found {len(mirrors)} mirrors.")
    except Exception as e:
        print(f"âš ï¸ Error fetching mirrors: {e}")
    
    # Ù‡Ù…ÛŒØ´Ù‡ Ø³Ø§ÛŒØª Ø§ØµÙ„ÛŒ Ø±Ø§ Ù‡Ù… Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ø§ÙˆÙ„ÛŒÙ† Ú¯Ø²ÛŒÙ†Ù‡ Ø§Ø¶Ø§ÙÙ‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
    if "http://www.vpngate.net" not in mirrors:
        mirrors.insert(0, "http://www.vpngate.net")
        
    return mirrors

def extract_from_html(url):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø² HTML Ø¨Ø±Ø§ÛŒ Ù¾ÙˆØ±Øªâ€ŒÙ‡Ø§ÛŒ Ø®Ø§Øµ"""
    hosts = []
    try:
        response = requests.get(url, headers=HEADERS, timeout=10)
        if response.status_code != 200: return []
        
        soup = BeautifulSoup(response.text, 'html.parser')
        pattern = re.compile(r"SSTP Hostname\s*:\s*([a-zA-Z0-9\.\-]+(?::\d+)?)")
        elements = soup.find_all(string=re.compile("SSTP Hostname"))

        for element in elements:
            parent_text = element.parent.get_text()
            match = pattern.search(parent_text)
            if match:
                hosts.append(match.group(1))
    except:
        pass
    return hosts

def fetch_csv_from_mirror(base_url):
    """Ø¯Ø§Ù†Ù„ÙˆØ¯ Ùˆ Ù¾Ø±Ø¯Ø§Ø²Ø´ CSV Ø§Ø² ÛŒÚ© Ø¢Ø¯Ø±Ø³ Ø®Ø§Øµ"""
    csv_url = f"{base_url}/{API_PATH}"
    hosts = []
    try:
        response = requests.get(csv_url, timeout=10)
        if response.status_code != 200: return []
        
        content = response.text
        lines = content.splitlines()
        csv_clean_lines = [line[1:] if line.startswith("#HostName") else line 
                          for line in lines if (line.startswith("#HostName") or (not line.startswith("*") and not line.startswith("#")))]
        
        f = io.StringIO("\n".join(csv_clean_lines))
        reader = csv.DictReader(f)
        
        for row in reader:
            hostname = row.get("HostName")
            if hostname:
                if ".opengw.net" not in hostname:
                    hosts.append(f"{hostname}.opengw.net")
                else:
                    hosts.append(hostname)
    except:
        pass
    return hosts

def send_to_telegram(file_path, caption):
    if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_ID:
        print("Telegram credentials missing.")
        return
    url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendDocument"
    try:
        with open(file_path, 'rb') as f:
            requests.post(url, data={'chat_id': TELEGRAM_CHAT_ID, 'caption': caption, 'parse_mode': 'Markdown'}, files={'document': f})
    except Exception as e:
        print(f"Telegram Error: {e}")

def main():
    start_time = time.time()
    
    # 1. Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª Ù…ÛŒØ±ÙˆØ±Ù‡Ø§
    mirrors = get_active_mirrors()
    
    # Ù„ÛŒØ³Øª Ù†Ù‡Ø§ÛŒÛŒ (Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² ØªÚ©Ø±Ø§Ø± Ùˆ Ù…Ø¯ÛŒØ±ÛŒØª Ù¾ÙˆØ±Øª)
    # Key: Domain, Value: Port (or None)
    final_hosts_map = {}

    # 2. Ø¯Ø±ÛŒØ§ÙØª Ø§Ø² HTML Ø³Ø§ÛŒØª Ø§ØµÙ„ÛŒ (Ø¨Ø±Ø§ÛŒ Ù¾ÙˆØ±Øªâ€ŒÙ‡Ø§ÛŒ Ø¯Ù‚ÛŒÙ‚)
    print("ğŸ“¥ Scraping Main HTML...")
    html_hosts = extract_from_html(MAIN_URL)
    for h in html_hosts:
        if ":" in h:
            domain, port = h.split(":")
            final_hosts_map[domain] = port
        else:
            final_hosts_map[h] = "443"

    # 3. Ø¯Ø±ÛŒØ§ÙØª CSV Ø§Ø² ØªÙ…Ø§Ù… Ù…ÛŒØ±ÙˆØ±Ù‡Ø§ (Ø¨Ù‡ ØµÙˆØ±Øª Ù‡Ù…Ø²Ù…Ø§Ù† Ø¨Ø±Ø§ÛŒ Ø³Ø±Ø¹Øª Ø¨ÛŒØ´ØªØ±)
    print(f"ğŸ“¥ Downloading CSVs from {len(mirrors)} sources (Parallel)...")
    
    with ThreadPoolExecutor(max_workers=10) as executor:
        future_to_url = {executor.submit(fetch_csv_from_mirror, url): url for url in mirrors}
        
        for future in as_completed(future_to_url):
            found_hosts = future.result()
            for domain in found_hosts:
                # Ø§Ú¯Ø± Ø¯Ø§Ù…Ù†Ù‡ Ù‚Ø¨Ù„Ø§Ù‹ Ø¨Ø§ Ù¾ÙˆØ±Øª Ø®Ø§Øµ (Ø§Ø² HTML) Ø§Ø¶Ø§ÙÙ‡ Ù†Ø´Ø¯Ù‡ Ø¨ÙˆØ¯ØŒ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†
                if domain not in final_hosts_map:
                    final_hosts_map[domain] = "DEFAULT" # Ø¹Ù„Ø§Ù…Øªâ€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù†Ù‡Ø§ÛŒÛŒ

    # 4. ÙØ±Ù…Øªâ€ŒØ¯Ù‡ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ø·Ø¨Ù‚ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø´Ù…Ø§
    # public-vpn -> Ø¨Ø¯ÙˆÙ† Ù¾ÙˆØ±Øª
    # Ø¨Ù‚ÛŒÙ‡ -> Ø§Ú¯Ø± Ù¾ÙˆØ±Øª Ø®Ø§Øµ Ø¯Ø§Ø´Øª (Ø§Ø² HTML) Ù‡Ù…Ø§Ù† Ù¾ÙˆØ±ØªØŒ Ø§Ú¯Ø± Ù†Ù‡ -> 443
    
    output_list = []
    for domain, port in final_hosts_map.items():
        if "public-vpn" in domain:
            output_list.append(domain) # Ø¨Ø¯ÙˆÙ† Ù¾ÙˆØ±Øª
        else:
            if port == "DEFAULT":
                output_list.append(f"{domain}:443")
            else:
                output_list.append(f"{domain}:{port}")

    output_list.sort()
    
    # Ø¢Ù…Ø§Ø±
    public_vpn_count = sum(1 for h in output_list if "public-vpn" in h)
    
    # Ø°Ø®ÛŒØ±Ù‡
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        for line in output_list:
            f.write(line + '\n')
            
    now = datetime.now().strftime("%Y-%m-%d %H:%M")
    summary_report = f"ğŸŒ *VPN Gate Ultimate Collector*\nğŸ“… Date: `{now}`\n\n"
    summary_report += f"ğŸ” Sources Checked: {len(mirrors)} Mirrors\n"
    summary_report += f"ğŸ“Š Stats:\n"
    summary_report += f"ğŸ”¹ Public-VPN (No Port): {public_vpn_count}\n"
    summary_report += f"ğŸ”¹ Others (With Port): {len(output_list) - public_vpn_count}\n"
    summary_report += f"{'-'*25}\n"
    summary_report += f"âœ… *Total Unique Hosts:* `{len(output_list)}`\n"
    summary_report += f"â± Time: `{int(time.time() - start_time)}s`"

    print(summary_report)

    zip_name = "SSTP_Ultimate.zip"
    with zipfile.ZipFile(zip_name, 'w', zipfile.ZIP_DEFLATED) as zipf:
        if os.path.exists(OUTPUT_FILE):
            zipf.write(OUTPUT_FILE, os.path.basename(OUTPUT_FILE))

    if IS_GITHUB:
        send_to_telegram(zip_name, summary_report)

if __name__ == "__main__":
    main()
